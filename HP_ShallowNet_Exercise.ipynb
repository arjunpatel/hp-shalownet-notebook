{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras\n",
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ShallowNet\n",
    "\n",
    "In this exercise, we’ll implement the ShallowNet architecture. As the name suggests, the\n",
    "ShallowNet architecture contains only a few layers – the entire network architecture can be\n",
    "summarized as: INPUT => CONV => RELU => FC.\n",
    "This simple network architecture will allow us to get our feet wet implementing Convolutional\n",
    "Neural Networks using the Keras library. After implementing ShallowNet, We will apply it to the\n",
    "CIFAR-10 dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "#from pyimagesearch.nn.conv import ShallowNet\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import cifar10\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lines above import our required Python packages. \n",
    "\n",
    "Let's have a look at our dataset:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] loading CIFAR-10 data...\")\n",
    "((trainX, trainY), (testX, testY)) = cifar10.load_data()\n",
    "trainX = trainX.astype(\"float\") / 255.0\n",
    "testX = testX.astype(\"float\") / 255.0\n",
    "print(\"[INFO] Finished loading CIFAR-10 data...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like MNIST, CIFAR-10 is considered another standard benchmark dataset for image classification\n",
    "in the computer vision and machine learning literature. CIFAR-10 consists of 60,000\n",
    "32X32X3 (RGB) images resulting in a feature vector dimensionality of 3072.\n",
    "As the name suggests, CIFAR-10 consists of 10 classes, including: airplanes, automobiles,\n",
    "birds, cats, deer, dogs, frogs, horses, ships, and trucks.\n",
    "While it’s quite easy to train a model that obtains > 97% classification accuracy on MNIST,\n",
    "it’s substantially harder to obtain such a model for CIFAR-10 (and it’s bigger brother, CIFAR-100).\n",
    "\n",
    "The challenge comes from the dramatic variance in how objects appear. For example, we can\n",
    "no longer assume that an image containing a green pixel at a given (x;y)-coordinate is a frog. This\n",
    "pixel could be part of the background of a forest that contains a deer. Or, the pixel could simply be\n",
    "the color of a green truck.\n",
    "These assumptions are a stark contrast to the MNIST dataset where the network can learn assumptions\n",
    "regarding the spatial distribution of pixel intensities. For example, the spatial distribution\n",
    "of foreground pixels of the number 1 is substantially different than a 0 or 5.\n",
    "While being a small dataset, CIFAR-10 is still regularly used to benchmark new CNN architectures.\n",
    "We load the training and testing data, then scale it into the range [0,1] .\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the train data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of the 10 first train labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY[0:10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of the second image in the dataset (truck):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure\n",
    "plt.imshow(trainX[1,:,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testY.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of the 10 first test labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testY[0:10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our labels are then one-hot encoded from integers to vectors :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY[0:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testY[0:10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the label names for the CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelNames = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n",
    " \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our workflow will be as follow: first we will present our neural network with the training data, `trainX` and `trainY`. The \n",
    "network will then learn to associate images and labels. Finally, we will ask the network to produce predictions for `testX`, and we \n",
    "will verify if these predictions match the labels from `testY`.\n",
    "\n",
    "Let's build our network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "# initialize the Shallownet model : \n",
    "#INPUT => 32 filters of 3X3 CONV => RELU => Flatten =>  FC with 10 neurons => softmax\n",
    " \n",
    "#keras help: \n",
    "#https://keras.io/getting-started/sequential-model-guide/\n",
    "#https://keras.io/layers/convolutional/  \n",
    "#https://keras.io/layers/core/\n",
    "\n",
    "model = Sequential()\n",
    "inputShape = (32, 32, 3)\n",
    "\n",
    "\n",
    "#Fill the lines below to complete the model... \n",
    "\n",
    "\n",
    "\n",
    "#show model summary:\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The core building block of neural networks is the \"layer\", a data-processing module which you can conceive as a \"filter\" for data. Some \n",
    "data comes in, and comes out in a more useful form. Precisely, layers extract _representations_ out of the data fed into them -- hopefully \n",
    "representations that are more meaningful for the problem at hand. Most of deep learning really consists of chaining together simple layers \n",
    "which will implement a form of progressive \"data distillation\". A deep learning model is like a sieve for data processing, made of a \n",
    "succession of increasingly refined data filters -- the \"layers\".\n",
    "\n",
    "Here our network consists of 'Conv2D' and 'Dense' (\"fully-connected\") layers. The last layer is a 10-way \"softmax\" layer, which means it will return an array of 10 probability scores (summing to 1). Each \n",
    "score will be the probability that the current image belongs to one of the 10 CIFAR-10 classes.\n",
    "\n",
    "To make our network ready for training, we need to pick three more things, as part of \"compilation\" step:\n",
    "\n",
    "* A loss function: the is how the network will be able to measure how good a job it is doing on its training data, and thus how it will be \n",
    "able to steer itself in the right direction.\n",
    "* An optimizer: this is the mechanism through which the network will update itself based on the data it sees and its loss function.\n",
    "* Metrics to monitor during training and testing. Here we will only care about accuracy (the fraction of the images that were correctly \n",
    "classified).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = SGD(lr=0.01)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to train our network, which in Keras is done via a call to the `fit` method of the network: \n",
    "we \"fit\" the model to its training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] training network...\")\n",
    "num_epochs = 5 # use less epochs in case of CPU installation\n",
    "H = model.fit(trainX, trainY, validation_data=(testX, testY),\n",
    "\tbatch_size=32, epochs=num_epochs, verbose=1)\n",
    "model.save('ShallowNetModel.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two quantities are being displayed during training: the \"loss\" of the network over the training/validation data, and the accuracy of the network over \n",
    "the training/validation data.\n",
    "\n",
    "Now let's check that our model performs well on the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##optional - load model from saved model\n",
    "#from keras.models import load_model\n",
    "#del model \n",
    "#model = load_model('ShallowNetModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "\tpredictions.argmax(axis=1), target_names=labelNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, num_epochs), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, num_epochs), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, num_epochs), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, num_epochs), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the training session is completed, 'play' with the following hyper-parameters \n",
    "(notice the accuracy, loss, training time):\n",
    "\n",
    "1. Remove the Relu layer and see what happens\n",
    "2. Learning rate- (0.1, 0.01, 0.001)\n",
    "3. Batch Size - (1,32,64)\n",
    "4. Number of epochs - (1,40,80)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: \n",
    "\n",
    "Adrian Rosebrock, Deep Learning For Computer Vision With Python -Starter Bundle (2018), Chapter 12 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
